{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71844df9-f876-43c2-aa1d-05373b953fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         # 导入pandas库，它就像一个超级强大的Excel工具，专门用来处理表格数据（DataFrame）。\n",
    "\n",
    "# 加载数据集并指定编码为gbk\n",
    "data = pd.read_csv('medical_data.csv',encoding='gbk')\n",
    "# 使用pandas的read_csv函数，读取名为 'medical_data.csv' 的CSV文件。\n",
    "# encoding='gbk' 参数是用来指定文件的编码格式为 'gbk'。\n",
    "# 这是因为中文系统下创建的CSV文件可能不是默认的 'utf-8' 编码，而是 'gbk' 或 'gb2312'，\n",
    "# 指定正确的编码可以避免中文乱码问题。\n",
    "# 将文件内容加载到一个名为 'data' 的DataFrame（可以理解为表格）中。\n",
    "\n",
    "# 查看数据类型\n",
    "print(data.dtypes)          # 打印出DataFrame中每一列的名称及其对应的数据类型（例如，int64、float64、object等）。\n",
    "                            # 了解数据类型对于后续的数据清洗和分析至关重要。\n",
    "# 查看表结构基本信息\n",
    "print(data.info())          # 打印DataFrame的概要信息，包括每列的非空值数量和数据类型，\n",
    "                            # 以及内存使用情况。这比 `dtypes` 更详细，可以快速识别哪些列可能存在缺失值。\n",
    "\n",
    "# 显示每一列的空缺值数量\n",
    "print(data.isnull().sum())  # `data.isnull()` 会创建一个与原DataFrame形状相同，但内容为True/False的DataFrame，\n",
    "                            # 其中True表示原始位置有缺失值（NaN）。\n",
    "                            # `.sum()` 会对这个True/False DataFrame进行求和，因为True被算作1，False被算作0，\n",
    "                            # 所以结果就是每一列缺失值的总数量。这有助于我们了解缺失值的分布情况。\n",
    "\n",
    "# 规范日期格式\n",
    "data['就诊日期'] = pd.to_datetime(data['就诊日期'])\n",
    "# 将 '就诊日期' 列转换为pandas的日期时间（datetime）格式。\n",
    "# `pd.to_datetime()` 函数能够灵活地解析多种日期字符串格式。\n",
    "# 这样做的好处是，可以让日期数据进行日期计算（例如，计算天数差）和更方便的筛选。\n",
    "data['诊断日期'] = pd.to_datetime(data['诊断日期'])\n",
    "# 同样地，将 '诊断日期' 列转换为日期时间格式。\n",
    "\n",
    "# 修改列名\n",
    "data.rename(columns={'病人ID': '患者ID'}, inplace=True)\n",
    "# 使用DataFrame的 .rename() 方法来修改列名。\n",
    "# `columns={'旧列名': '新列名'}` 是一个字典，指定了要修改的列名映射关系。\n",
    "# `inplace=True` 表示直接在原始DataFrame 'data' 上进行修改，而不是返回一个新的DataFrame。\n",
    "\n",
    "# 查看修改后的表结构\n",
    "print(data.head())          # 再次显示数据的前5行，确认列名 '病人ID' 是否已成功修改为 '患者ID'。\n",
    "\n",
    "from datetime import datetime # 从Python的内置 `datetime` 模块中导入 `datetime` 类，用于处理日期和时间。\n",
    "\n",
    "# 增加诊断延迟和病程列\n",
    "data['诊断延迟'] = (data['诊断日期'] - data['就诊日期']).dt.days\n",
    "# 新增一列名为 '诊断延迟'。\n",
    "# `data['诊断日期'] - data['就诊日期']`：由于这两列已经转换为日期时间格式，可以直接相减，结果是一个时间差（Timedelta）Series。\n",
    "# `.dt.days`：从时间差Series中提取出天数部分。\n",
    "# 这样，'诊断延迟' 列就表示从就诊到诊断之间相隔的天数。\n",
    "data['病程'] = (datetime(2024, 9, 1) - data['诊断日期']).dt.days\n",
    "# 新增一列名为 '病程'。\n",
    "# `datetime(2024, 9, 1)`：定义一个固定的参考日期（这里是2024年9月1日）。\n",
    "# `datetime(...) - data['诊断日期']`：计算参考日期与每个病人的诊断日期之间的时间差。\n",
    "# `.dt.days`：提取出天数部分。这样，'病程' 列表示从诊断日期到2024年9月1日之间相隔的天数。\n",
    "\n",
    "# 删除不合理的数据\n",
    "data = data[(data['诊断延迟'] >= 0) & (data['年龄'] > 0) & (data['年龄'] < 120)]\n",
    "# 这一行代码是进行数据筛选，删除不符合逻辑或不合理的数据记录。\n",
    "# `(data['诊断延迟'] >= 0)`：筛选出 '诊断延迟' 不为负数的行（诊断日期应该不早于就诊日期）。\n",
    "# `(data['年龄'] > 0)`：筛选出年龄大于0的行（年龄不能为0或负数）。\n",
    "# `(data['年龄'] < 120)`：筛选出年龄小于120的行（通常将大于某个极端值的年龄视为不合理或录入错误）。\n",
    "# `&`：是逻辑“与”操作符，表示必须同时满足所有这些条件，行才会被保留。\n",
    "# 通过这些条件，我们移除了数据中一些明显错误或不符合实际情况的记录。\n",
    "\n",
    "# 查看修改后的数据\n",
    "print(data.describe())      # 打印DataFrame的描述性统计信息。\n",
    "                            # 这包括了数值列的计数、均值、标准差、最小值、25%分位数(Q1)、中位数(50%分位数/Q2)、\n",
    "                            # 75%分位数(Q3)和最大值。这有助于我们快速了解数据分布和特征的统计特性。\n",
    "\n",
    "# 删除重复值并记录删除的行数\n",
    "initial_rows = data.shape[0]        # 记录处理前的数据总行数。\n",
    "data.drop_duplicates(inplace=True)  # 使用DataFrame的 .drop_duplicates() 方法，删除DataFrame中所有完全相同的重复行。\n",
    "                                    # `inplace=True` 表示直接在原始DataFrame 'data' 上修改。\n",
    "deleted_rows = initial_rows - data.shape[0] # 计算删除了多少行：初始行数减去处理后的行数。\n",
    "\n",
    "print(f'删除的重复行数: {deleted_rows}') # 打印出总共删除了多少重复行。\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # 从scikit-learn库中导入MinMaxScaler，这是一个用于数据归一化的工具。\n",
    "\n",
    "# 对需要归一化的列进行处理\n",
    "scaler = MinMaxScaler()             # 创建一个MinMaxScaler的实例（一个“归一化工具”）。\n",
    "columns_to_normalize = ['年龄', '体重', '身高'] # 定义一个列表，包含我们想要进行归一化处理的列名。\n",
    "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n",
    "# data[columns_to_normalize]：选取DataFrame `data` 中所有需要归一化的列。\n",
    "# scaler.fit_transform(...)：这是MinMaxScaler的核心方法。它做了两件事：\n",
    "#   1. `fit`：在选定列中找到每个列的最小值（min）和最大值（max）。\n",
    "#   2. `transform`：对选定列中的每个值进行归一化处理，将数据缩放到0到1之间。\n",
    "#                     具体公式是：(原始值 - 最小值) / (最大值 - 最小值)。\n",
    "# 归一化有助于消除不同特征之间的量纲影响，确保所有特征在模型训练时具有相同的权重。\n",
    "# 将归一化后的结果重新赋值回 `data` 的相应列中。\n",
    "\n",
    "# 查看归一化后的数据\n",
    "print(data.head())                  # 再次显示数据的前5行，检查 '年龄'、'体重'、'身高' 列的值是否已被归一化到0-1之间。\n",
    "\n",
    "import matplotlib.pyplot as plt     # 导入matplotlib.pyplot库，主要用于创建静态、动态交互式的可视化图表。\n",
    "import matplotlib.font_manager as fm # 导入matplotlib.font_manager库，用于管理和查找字体，特别是处理中文字体。\n",
    "\n",
    "\n",
    "# 统计治疗结果分布\n",
    "treatment_outcome_distribution = data.groupby('疾病类型')['治疗结果'].value_counts().unstack()\n",
    "# `data.groupby('疾病类型')`：按 '疾病类型' 列对数据进行分组。\n",
    "# `['治疗结果'].value_counts()`：在每个疾病类型组内，统计 '治疗结果' 列中每个值的出现次数。\n",
    "# `.unstack()`：将多级索引的Series转换为DataFrame，使 '治疗结果' 的不同类别成为列。\n",
    "# 这样，`treatment_outcome_distribution`就会是一个DataFrame，行是疾病类型，列是治疗结果的种类，值为每种组合的数量。\n",
    "\n",
    "# 设置中文字体\n",
    "font_path = 'C:/Windows/Fonts/simhei.ttf'  # 根据你的系统调整字体路径\n",
    "# 定义一个变量 `font_path`，存储系统中常用中文字体（例如“黑体”）的文件路径。\n",
    "# 注意：这个路径在不同操作系统或不同用户环境下可能需要调整。\n",
    "my_font = fm.FontProperties(fname=font_path)\n",
    "# 使用 `matplotlib.font_manager.FontProperties` 创建一个字体属性对象，\n",
    "# 指定使用 `font_path` 指向的字体文件，以便matplotlib正确显示中文。\n",
    "\n",
    "# 绘制柱状图\n",
    "treatment_outcome_distribution.plot(kind='bar', stacked=True)\n",
    "# 使用DataFrame的内置 `plot()` 方法绘制柱状图。\n",
    "# `kind='bar'` 指定图表类型为柱状图。\n",
    "# `stacked=True` 表示柱子是堆叠的，即不同治疗结果的计数在每个疾病类型的柱子上堆叠显示。\n",
    "plt.title('不同疾病类型的治疗结果分布', fontproperties=my_font)\n",
    "# 设置图表的标题，并使用之前定义好的 `my_font` 来显示中文标题。\n",
    "plt.xlabel('疾病类型', fontproperties=my_font)\n",
    "# 设置x轴标签，并使用 `my_font` 显示中文。\n",
    "plt.ylabel('治疗结果数量', fontproperties=my_font)\n",
    "# 设置y轴标签，并使用 `my_font` 显示中文。\n",
    "plt.xticks(fontproperties=my_font)  # 设置x轴刻度标签的字体\n",
    "# 同样地，设置x轴上的刻度标签（例如疾病类型的名称）的字体为 `my_font`，以确保中文正常显示。\n",
    "plt.yticks(fontproperties=my_font)  # 设置y轴刻度标签的字体\n",
    "# 设置y轴上的刻度标签（例如数量）的字体为 `my_font`。\n",
    "plt.legend(prop=my_font)  # 设置图例字体\n",
    "# 设置图例（区分不同治疗结果颜色的方块和文本）的字体为 `my_font`。\n",
    "plt.show()                          # 显示绘制好的柱状图。\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(data['年龄'], data['疾病严重程度'])\n",
    "# 使用 `plt.scatter()` 函数绘制散点图。\n",
    "# `data['年龄']` 作为x轴数据，`data['疾病严重程度']` 作为y轴数据。\n",
    "plt.title('年龄和疾病严重程度的关系', fontproperties=my_font)\n",
    "# 设置散点图的标题。\n",
    "plt.xlabel('年龄', fontproperties=my_font)\n",
    "# 设置x轴标签。\n",
    "plt.ylabel('疾病严重程度', fontproperties=my_font)\n",
    "# 设置y轴标签。\n",
    "plt.xticks(fontproperties=my_font)  # 设置x轴刻度标签的字体\n",
    "# 设置x轴刻度标签的字体。\n",
    "plt.yticks(fontproperties=my_font)  # 设置y轴刻度标签的字体\n",
    "# 设置y轴刻度标签的字体。\n",
    "plt.legend(prop=my_font)  # 设置图例字体\n",
    "# 注意：这个散点图没有明确的图例，`plt.legend()` 在此处可能不会显示任何内容，\n",
    "# 但如果后续添加了多个散点系列，`prop=my_font` 会起作用。\n",
    "plt.show()                          # 显示绘制好的散点图。\n",
    "\n",
    "# 保存处理后得数据\n",
    "output_path = '2.1.4_cleaned_data.csv' # 定义保存文件的路径和名称。\n",
    "data.to_csv(output_path, index=False)\n",
    "# `data.to_csv(...)`：这是pandas用来将DataFrame保存为CSV文件的方法。\n",
    "# `output_path`：指定新保存的文件的路径和名称。\n",
    "# `index=False`：这个参数非常重要，它表示在保存CSV文件时，不要把DataFrame的索引（左边默认从0开始的数字序号）也写入到CSV文件中。\n",
    "# 这样做可以避免文件中有额外且无用的列。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
