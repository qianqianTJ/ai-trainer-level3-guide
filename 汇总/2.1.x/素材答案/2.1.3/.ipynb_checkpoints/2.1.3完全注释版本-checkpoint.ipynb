{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31bd25-45f7-4f60-962d-b2e5103fff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         # 导入pandas库，它就像一个超级强大的Excel工具，专门用来处理表格数据（DataFrame）。\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('finance数据集.csv') # 使用pandas的read_csv函数，读取名为 'finance数据集.csv' 的CSV文件。\n",
    "                                        # 将文件内容加载到一个名为 'data' 的DataFrame（可以理解为表格）中。\n",
    "\n",
    "# 显示前五行的数据\n",
    "print(data.head())                      # 使用DataFrame的 .head() 方法，显示数据的前5行。\n",
    "                                        # 这能帮助我们快速查看数据的基本结构、列名和前几条记录，初步了解数据长什么样。\n",
    "\n",
    "import matplotlib.pyplot as plt         # 导入matplotlib.pyplot库，主要用于创建静态、动态交互式的可视化图表。\n",
    "import seaborn as sns                   # 导入seaborn库，它基于matplotlib，提供了一个高级界面，用于绘制引人入胜的统计图形。\n",
    "\n",
    "# 设置图像尺寸\n",
    "plt.figure(figsize=(12, 8))             # 创建一个新的图形窗口，并设置其大小为12英寸宽、8英寸高。\n",
    "\n",
    "# 识别数值列用于箱线图\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "# data.select_dtypes(include=['float64', 'int64'])：从DataFrame 'data' 中选择所有数据类型为浮点数（float64）和整数（int64）的列。\n",
    "# .columns：从这些选定的数值列中提取它们的列名。\n",
    "# 将这些数值列的名称存储在 `numeric_cols` 列表中，以便后续对这些列进行可视化和异常值处理。\n",
    "\n",
    "# 创建箱线图\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    # 遍历 `numeric_cols` 列表中的每个数值列名。\n",
    "    # enumerate(..., 1) 会为每个列名生成一个从1开始的索引 `i` 和列名 `col`。\n",
    "    plt.subplot(3, 4, i)                # 创建一个子图网格。\n",
    "                                        # plt.subplot(nrows, ncols, index) 表示创建一个 3行4列 的子图网格，\n",
    "                                        # 当前子图的位置是 `index`（即 `i`）。\n",
    "                                        # 例如，第一次循环 `i=1`，子图在第一行第一列。\n",
    "    sns.boxplot(x=data[col])            # 使用seaborn的 `boxplot` 函数绘制箱线图。\n",
    "                                        # `x=data[col]` 表示以当前列 `col` 的数据作为输入来绘制箱线图。\n",
    "                                        # 箱线图可以直观地显示数据的分布、中位数、四分位数，以及潜在的异常值。\n",
    "    plt.title(col)                      # 设置当前子图的标题为当前列的名称 `col`。\n",
    "\n",
    "plt.tight_layout()                      # 自动调整子图参数，使之填充整个图形区域，并避免图例或标签重叠。\n",
    "plt.show()                              # 显示所有绘制好的箱线图。\n",
    "\n",
    "# 使用IQR处理异常值\n",
    "Q1 = data[numeric_cols].quantile(0.25)  # 计算所有数值列的第一个四分位数（Q1，即25%分位数）。\n",
    "Q3 = data[numeric_cols].quantile(0.75)  # 计算所有数值列的第三个四分位数（Q3，即75%分位数）。\n",
    "IQR = Q3-Q1                             # 计算四分位距（IQR），即 Q3 - Q1。IQR表示数据中间50%的范围。\n",
    "\n",
    "# 移除异常值\n",
    "data_cleaned = data[~((data[numeric_cols] < (Q1 - 1.5 * IQR)) | (data[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "# 这一行代码是使用IQR（四分位距）方法来识别和删除异常值。\n",
    "# (Q1 - 1.5 * IQR)：计算下限。任何低于这个值的数据点都被认为是异常值。\n",
    "# (Q3 + 1.5 * IQR)：计算上限。任何高于这个值的数据点都被认为是异常值。\n",
    "# (data[numeric_cols] < (Q1 - 1.5 * IQR))：检查所有数值列中哪些值小于下限。\n",
    "# (data[numeric_cols] > (Q3 + 1.5 * IQR))：检查所有数值列中哪些值大于上限。\n",
    "# |：逻辑“或”操作符，表示只要满足其中一个条件（小于下限 或 大于上限）就视为异常。\n",
    "# .any(axis=1)：对每一行进行检查。如果一行中任何一个数值列的值满足异常值条件，则这一行被标记为True（异常）。\n",
    "# ~：逻辑“非”操作符，它将所有被标记为True（异常）的行反转为False，将False（正常）的行反转为True。\n",
    "# data[...]：使用这个反转后的True/False系列来筛选原始 `data` DataFrame。\n",
    "# 这样，`data_cleaned` 只会包含那些所有数值列的值都在合理范围内的行，即移除了异常值。\n",
    "\n",
    "# 检查处理重复值\n",
    "duplicates = data_cleaned.duplicated()  # `data_cleaned.duplicated()` 会返回一个布尔系列（True/False），\n",
    "                                        # 其中True表示该行是与之前某行完全重复的。\n",
    "num_duplicates = duplicates.sum()       # 对布尔系列求和，计算出重复行的总数量（True算作1）。\n",
    "data_cleaned = data_cleaned[~duplicates] # 使用逻辑“非” `~` 反转 `duplicates` 系列，\n",
    "                                        # 这样可以将所有重复的行（True）变为False，非重复的行（False）变为True。\n",
    "                                        # 然后用这个布尔系列来筛选 `data_cleaned`，从而删除所有重复的行。\n",
    "\n",
    "print(f'删除的重复行数: {num_duplicates}') # 打印出总共删除了多少重复行。\n",
    "\n",
    "#对数据进行归一化处理\n",
    "from sklearn.preprocessing import MinMaxScaler # 从scikit-learn库中导入MinMaxScaler，这是一个用于数据归一化的工具。\n",
    "\n",
    "scaler = MinMaxScaler()                 # 创建一个MinMaxScaler的实例（一个“归一化工具”）。\n",
    "data_cleaned[numeric_cols] = scaler.fit_transform(data_cleaned[numeric_cols])\n",
    "# data_cleaned[numeric_cols]：选取DataFrame `data_cleaned` 中所有需要归一化的数值列。\n",
    "# scaler.fit_transform(...)：这是MinMaxScaler的核心方法。它做了两件事：\n",
    "#   1. `fit`：在选定列中找到每个列的最小值（min）和最大值（max）。\n",
    "#   2. `transform`：对选定列中的每个值进行归一化处理，将数据缩放到0到1之间。\n",
    "#                     具体公式是：(原始值 - 最小值) / (最大值 - 最小值)。\n",
    "# 归一化有助于消除不同特征之间的量纲影响，确保所有特征在模型训练时具有相同的权重。\n",
    "# 将归一化后的结果重新赋值回 `data_cleaned` 的相应列中。\n",
    "\n",
    "# 设定目标变量\n",
    "target_variable = 'SeriousDlqin2yrs'    # 定义目标变量的列名，这个变量是我们要预测的目标。\n",
    "\n",
    "from sklearn.model_selection import train_test_split # 从scikit-learn库中导入train_test_split，这是一个用于分割数据集的工具。\n",
    "\n",
    "# 定义特征和目标\n",
    "X = data_cleaned.drop(columns=[target_variable,'Unnamed: 0'])   #1分\n",
    "# data_cleaned.drop(columns=[target_variable,'Unnamed: 0'])：从 `data_cleaned` DataFrame 中删除指定的列。\n",
    "# `target_variable`：确保目标变量不会被当作特征。\n",
    "# `'Unnamed: 0'`：通常是CSV文件在保存时自动生成的无用索引列，在这里将其删除以作为特征。\n",
    "# 将剩余的列作为特征矩阵，赋值给 `X`。\n",
    "y = data_cleaned[target_variable]                         #1分\n",
    "# 从 `data_cleaned` DataFrame 中选取目标变量列 `target_variable`，赋值给 `y`。\n",
    "\n",
    "# 划分数据（训练集占80%）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "# train_test_split 是一个非常重要的函数，它将我们的数据集分割成四个部分：\n",
    "#   X_train：用于训练模型的特征数据（80%）。\n",
    "#   X_test：用于评估模型的特征数据（20%，模型在训练中看不到）。\n",
    "#   y_train：用于训练模型的目标变量（80%）。\n",
    "#   y_test：用于评估模型的目标变量（20%）。\n",
    "# test_size=0.2：指定测试集占总数据集的比例是20%（即0.2），那么训练集就占80%。\n",
    "# random_state=42：这是一个随机种子。设置这个参数可以确保每次运行代码时，数据集的划分结果都是相同的，\n",
    "# 这样保证了实验的可复现性。\n",
    "\n",
    "# 显示划分后的数据形状\n",
    "print(f'训练数据形状: {X_train.shape}') # 打印训练集特征矩阵 `X_train` 的行数和列数。\n",
    "print(f'测试数据形状: {X_test.shape}') # 打印测试集特征矩阵 `X_test` 的行数和列数。\n",
    "\n",
    "# 保存清洗后的数据到CSV\n",
    "cleaned_file_path = '2.1.3_cleaned_data.csv' # 定义保存文件的路径和名称。\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "# `data_cleaned.to_csv(...)`：这是pandas用来将DataFrame保存为CSV文件的方法。\n",
    "# `cleaned_file_path`：指定新保存的文件的路径和名称。\n",
    "# `index=False`：这个参数非常重要，它表示在保存CSV文件时，不要把DataFrame的索引（左边默认从0开始的数字序号）也写入到CSV文件中。\n",
    "# 这样做可以避免文件中有额外且无用的列。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
